{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3cee3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57b21b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "crim",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "zn",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "indus",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "chas",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "nox",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rm",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dis",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rad",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tax",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ptratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "black",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lstat",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "medv",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "3058ffaf-f6fd-4e55-8f30-7fa081ba885b",
       "rows": [
        [
         "0",
         "0.00632",
         "18.0",
         "2.31",
         "0",
         "0.538",
         "6.575",
         "65.2",
         "4.09",
         "1",
         "296",
         "15.3",
         "396.9",
         "4.98",
         "24.0"
        ],
        [
         "1",
         "0.02731",
         "0.0",
         "7.07",
         "0",
         "0.469",
         "6.421",
         "78.9",
         "4.9671",
         "2",
         "242",
         "17.8",
         "396.9",
         "9.14",
         "21.6"
        ],
        [
         "2",
         "0.02729",
         "0.0",
         "7.07",
         "0",
         "0.469",
         "7.185",
         "61.1",
         "4.9671",
         "2",
         "242",
         "17.8",
         "392.83",
         "4.03",
         "34.7"
        ],
        [
         "3",
         "0.03237",
         "0.0",
         "2.18",
         "0",
         "0.458",
         "6.998",
         "45.8",
         "6.0622",
         "3",
         "222",
         "18.7",
         "394.63",
         "2.94",
         "33.4"
        ],
        [
         "4",
         "0.06905",
         "0.0",
         "2.18",
         "0",
         "0.458",
         "7.147",
         "54.2",
         "6.0622",
         "3",
         "222",
         "18.7",
         "396.9",
         "5.33",
         "36.2"
        ],
        [
         "5",
         "0.02985",
         "0.0",
         "2.18",
         "0",
         "0.458",
         "6.43",
         "58.7",
         "6.0622",
         "3",
         "222",
         "18.7",
         "394.12",
         "5.21",
         "28.7"
        ],
        [
         "6",
         "0.08829",
         "12.5",
         "7.87",
         "0",
         "0.524",
         "6.012",
         "66.6",
         "5.5605",
         "5",
         "311",
         "15.2",
         "395.6",
         "12.43",
         "22.9"
        ],
        [
         "7",
         "0.14455",
         "12.5",
         "7.87",
         "0",
         "0.524",
         "6.172",
         "96.1",
         "5.9505",
         "5",
         "311",
         "15.2",
         "396.9",
         "19.15",
         "27.1"
        ],
        [
         "8",
         "0.21124",
         "12.5",
         "7.87",
         "0",
         "0.524",
         "5.631",
         "100.0",
         "6.0821",
         "5",
         "311",
         "15.2",
         "386.63",
         "29.93",
         "16.5"
        ],
        [
         "9",
         "0.17004",
         "12.5",
         "7.87",
         "0",
         "0.524",
         "6.004",
         "85.9",
         "6.5921",
         "5",
         "311",
         "15.2",
         "386.71",
         "17.1",
         "18.9"
        ],
        [
         "10",
         "0.22489",
         "12.5",
         "7.87",
         "0",
         "0.524",
         "6.377",
         "94.3",
         "6.3467",
         "5",
         "311",
         "15.2",
         "392.52",
         "20.45",
         "15.0"
        ],
        [
         "11",
         "0.11747",
         "12.5",
         "7.87",
         "0",
         "0.524",
         "6.009",
         "82.9",
         "6.2267",
         "5",
         "311",
         "15.2",
         "396.9",
         "13.27",
         "18.9"
        ],
        [
         "12",
         "0.09378",
         "12.5",
         "7.87",
         "0",
         "0.524",
         "5.889",
         "39.0",
         "5.4509",
         "5",
         "311",
         "15.2",
         "390.5",
         "15.71",
         "21.7"
        ],
        [
         "13",
         "0.62976",
         "0.0",
         "8.14",
         "0",
         "0.538",
         "5.949",
         "61.8",
         "4.7075",
         "4",
         "307",
         "21.0",
         "396.9",
         "8.26",
         "20.4"
        ],
        [
         "14",
         "0.63796",
         "0.0",
         "8.14",
         "0",
         "0.538",
         "6.096",
         "84.5",
         "4.4619",
         "4",
         "307",
         "21.0",
         "380.02",
         "10.26",
         "18.2"
        ],
        [
         "15",
         "0.62739",
         "0.0",
         "8.14",
         "0",
         "0.538",
         "5.834",
         "56.5",
         "4.4986",
         "4",
         "307",
         "21.0",
         "395.62",
         "8.47",
         "19.9"
        ],
        [
         "16",
         "1.05393",
         "0.0",
         "8.14",
         "0",
         "0.538",
         "5.935",
         "29.3",
         "4.4986",
         "4",
         "307",
         "21.0",
         "386.85",
         "6.58",
         "23.1"
        ],
        [
         "17",
         "0.7842",
         "0.0",
         "8.14",
         "0",
         "0.538",
         "5.99",
         "81.7",
         "4.2579",
         "4",
         "307",
         "21.0",
         "386.75",
         "14.67",
         "17.5"
        ],
        [
         "18",
         "0.80271",
         "0.0",
         "8.14",
         "0",
         "0.538",
         "5.456",
         "36.6",
         "3.7965",
         "4",
         "307",
         "21.0",
         "288.99",
         "11.69",
         "20.2"
        ],
        [
         "19",
         "0.7258",
         "0.0",
         "8.14",
         "0",
         "0.538",
         "5.727",
         "69.5",
         "3.7965",
         "4",
         "307",
         "21.0",
         "390.95",
         "11.28",
         "18.2"
        ],
        [
         "20",
         "1.25179",
         "0.0",
         "8.14",
         "0",
         "0.538",
         "5.57",
         "98.1",
         "3.7979",
         "4",
         "307",
         "21.0",
         "376.57",
         "21.02",
         "13.6"
        ],
        [
         "21",
         "0.85204",
         "0.0",
         "8.14",
         "0",
         "0.538",
         "5.965",
         "89.2",
         "4.0123",
         "4",
         "307",
         "21.0",
         "392.53",
         "13.83",
         "19.6"
        ],
        [
         "22",
         "1.23247",
         "0.0",
         "8.14",
         "0",
         "0.538",
         "6.142",
         "91.7",
         "3.9769",
         "4",
         "307",
         "21.0",
         "396.9",
         "18.72",
         "15.2"
        ],
        [
         "23",
         "0.98843",
         "0.0",
         "8.14",
         "0",
         "0.538",
         "5.813",
         "100.0",
         "4.0952",
         "4",
         "307",
         "21.0",
         "394.54",
         "19.88",
         "14.5"
        ],
        [
         "24",
         "0.75026",
         "0.0",
         "8.14",
         "0",
         "0.538",
         "5.924",
         "94.1",
         "4.3996",
         "4",
         "307",
         "21.0",
         "394.33",
         "16.3",
         "15.6"
        ],
        [
         "25",
         "0.84054",
         "0.0",
         "8.14",
         "0",
         "0.538",
         "5.599",
         "85.7",
         "4.4546",
         "4",
         "307",
         "21.0",
         "303.42",
         "16.51",
         "13.9"
        ],
        [
         "26",
         "0.67191",
         "0.0",
         "8.14",
         "0",
         "0.538",
         "5.813",
         "90.3",
         "4.682",
         "4",
         "307",
         "21.0",
         "376.88",
         "14.81",
         "16.6"
        ],
        [
         "27",
         "0.95577",
         "0.0",
         "8.14",
         "0",
         "0.538",
         "6.047",
         "88.8",
         "4.4534",
         "4",
         "307",
         "21.0",
         "306.38",
         "17.28",
         "14.8"
        ],
        [
         "28",
         "0.77299",
         "0.0",
         "8.14",
         "0",
         "0.538",
         "6.495",
         "94.4",
         "4.4547",
         "4",
         "307",
         "21.0",
         "387.94",
         "12.8",
         "18.4"
        ],
        [
         "29",
         "1.00245",
         "0.0",
         "8.14",
         "0",
         "0.538",
         "6.674",
         "87.3",
         "4.239",
         "4",
         "307",
         "21.0",
         "380.23",
         "11.98",
         "21.0"
        ],
        [
         "30",
         "1.13081",
         "0.0",
         "8.14",
         "0",
         "0.538",
         "5.713",
         "94.1",
         "4.233",
         "4",
         "307",
         "21.0",
         "360.17",
         "22.6",
         "12.7"
        ],
        [
         "31",
         "1.35472",
         "0.0",
         "8.14",
         "0",
         "0.538",
         "6.072",
         "100.0",
         "4.175",
         "4",
         "307",
         "21.0",
         "376.73",
         "13.04",
         "14.5"
        ],
        [
         "32",
         "1.38799",
         "0.0",
         "8.14",
         "0",
         "0.538",
         "5.95",
         "82.0",
         "3.99",
         "4",
         "307",
         "21.0",
         "232.6",
         "27.71",
         "13.2"
        ],
        [
         "33",
         "1.15172",
         "0.0",
         "8.14",
         "0",
         "0.538",
         "5.701",
         "95.0",
         "3.7872",
         "4",
         "307",
         "21.0",
         "358.77",
         "18.35",
         "13.1"
        ],
        [
         "34",
         "1.61282",
         "0.0",
         "8.14",
         "0",
         "0.538",
         "6.096",
         "96.9",
         "3.7598",
         "4",
         "307",
         "21.0",
         "248.31",
         "20.34",
         "13.5"
        ],
        [
         "35",
         "0.06417",
         "0.0",
         "5.96",
         "0",
         "0.499",
         "5.933",
         "68.2",
         "3.3603",
         "5",
         "279",
         "19.2",
         "396.9",
         "9.68",
         "18.9"
        ],
        [
         "36",
         "0.09744",
         "0.0",
         "5.96",
         "0",
         "0.499",
         "5.841",
         "61.4",
         "3.3779",
         "5",
         "279",
         "19.2",
         "377.56",
         "11.41",
         "20.0"
        ],
        [
         "37",
         "0.08014",
         "0.0",
         "5.96",
         "0",
         "0.499",
         "5.85",
         "41.5",
         "3.9342",
         "5",
         "279",
         "19.2",
         "396.9",
         "8.77",
         "21.0"
        ],
        [
         "38",
         "0.17505",
         "0.0",
         "5.96",
         "0",
         "0.499",
         "5.966",
         "30.2",
         "3.8473",
         "5",
         "279",
         "19.2",
         "393.43",
         "10.13",
         "24.7"
        ],
        [
         "39",
         "0.02763",
         "75.0",
         "2.95",
         "0",
         "0.428",
         "6.595",
         "21.8",
         "5.4011",
         "3",
         "252",
         "18.3",
         "395.63",
         "4.32",
         "30.8"
        ],
        [
         "40",
         "0.03359",
         "75.0",
         "2.95",
         "0",
         "0.428",
         "7.024",
         "15.8",
         "5.4011",
         "3",
         "252",
         "18.3",
         "395.62",
         "1.98",
         "34.9"
        ],
        [
         "41",
         "0.12744",
         "0.0",
         "6.91",
         "0",
         "0.448",
         "6.77",
         "2.9",
         "5.7209",
         "3",
         "233",
         "17.9",
         "385.41",
         "4.84",
         "26.6"
        ],
        [
         "42",
         "0.1415",
         "0.0",
         "6.91",
         "0",
         "0.448",
         "6.169",
         "6.6",
         "5.7209",
         "3",
         "233",
         "17.9",
         "383.37",
         "5.81",
         "25.3"
        ],
        [
         "43",
         "0.15936",
         "0.0",
         "6.91",
         "0",
         "0.448",
         "6.211",
         "6.5",
         "5.7209",
         "3",
         "233",
         "17.9",
         "394.46",
         "7.44",
         "24.7"
        ],
        [
         "44",
         "0.12269",
         "0.0",
         "6.91",
         "0",
         "0.448",
         "6.069",
         "40.0",
         "5.7209",
         "3",
         "233",
         "17.9",
         "389.39",
         "9.55",
         "21.2"
        ],
        [
         "45",
         "0.17142",
         "0.0",
         "6.91",
         "0",
         "0.448",
         "5.682",
         "33.8",
         "5.1004",
         "3",
         "233",
         "17.9",
         "396.9",
         "10.21",
         "19.3"
        ],
        [
         "46",
         "0.18836",
         "0.0",
         "6.91",
         "0",
         "0.448",
         "5.786",
         "33.3",
         "5.1004",
         "3",
         "233",
         "17.9",
         "396.9",
         "14.15",
         "20.0"
        ],
        [
         "47",
         "0.22927",
         "0.0",
         "6.91",
         "0",
         "0.448",
         "6.03",
         "85.5",
         "5.6894",
         "3",
         "233",
         "17.9",
         "392.74",
         "18.8",
         "16.6"
        ],
        [
         "48",
         "0.25387",
         "0.0",
         "6.91",
         "0",
         "0.448",
         "5.399",
         "95.3",
         "5.87",
         "3",
         "233",
         "17.9",
         "396.9",
         "30.81",
         "14.4"
        ],
        [
         "49",
         "0.21977",
         "0.0",
         "6.91",
         "0",
         "0.448",
         "5.602",
         "62.0",
         "6.0877",
         "3",
         "233",
         "17.9",
         "396.9",
         "16.2",
         "19.4"
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 506
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273   \n",
       "\n",
       "     ptratio   black  lstat  medv  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99   9.67  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = pd.read_csv('../datasets/Boston.csv')\n",
    "boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d9cd818",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = boston.drop('medv', axis = 1)\n",
    "y = boston['medv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a1aef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c6c5361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e-03 5.18206897e-01 1.03541379e+00 1.55262069e+00\n",
      " 2.06982759e+00 2.58703448e+00 3.10424138e+00 3.62144828e+00\n",
      " 4.13865517e+00 4.65586207e+00 5.17306897e+00 5.69027586e+00\n",
      " 6.20748276e+00 6.72468966e+00 7.24189655e+00 7.75910345e+00\n",
      " 8.27631034e+00 8.79351724e+00 9.31072414e+00 9.82793103e+00\n",
      " 1.03451379e+01 1.08623448e+01 1.13795517e+01 1.18967586e+01\n",
      " 1.24139655e+01 1.29311724e+01 1.34483793e+01 1.39655862e+01\n",
      " 1.44827931e+01 1.50000000e+01]\n",
      "[0.         0.11111111 0.22222222 0.33333333 0.44444444 0.55555556\n",
      " 0.66666667 0.77777778 0.88888889 1.        ]\n"
     ]
    }
   ],
   "source": [
    "alphas = np.linspace(0.001, 15, 30)\n",
    "l1 = np.linspace(0,1,10)\n",
    "print(alphas)\n",
    "print(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8482935c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.031e+08, tolerance: 3.465e+05\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.222e+08, tolerance: 3.465e+05\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.578e+08, tolerance: 3.465e+05\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.843e+08, tolerance: 3.465e+05\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.068e+08, tolerance: 3.465e+05\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.267e+08, tolerance: 3.465e+05\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.448e+08, tolerance: 3.465e+05\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.614e+08, tolerance: 3.465e+05\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.768e+08, tolerance: 3.465e+05\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.913e+08, tolerance: 3.465e+05\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.049e+08, tolerance: 3.465e+05\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.178e+08, tolerance: 3.465e+05\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.301e+08, tolerance: 3.465e+05\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.418e+08, tolerance: 3.465e+05\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.531e+08, tolerance: 3.465e+05\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.639e+08, tolerance: 3.465e+05\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.743e+08, tolerance: 3.465e+05\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.844e+08, tolerance: 3.465e+05\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.941e+08, tolerance: 3.465e+05\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.036e+08, tolerance: 3.465e+05\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.127e+08, tolerance: 3.465e+05\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.216e+08, tolerance: 3.465e+05\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.302e+08, tolerance: 3.465e+05\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.387e+08, tolerance: 3.465e+05\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.469e+08, tolerance: 3.465e+05\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.548e+08, tolerance: 3.465e+05\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.627e+08, tolerance: 3.465e+05\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.703e+08, tolerance: 3.465e+05\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.777e+08, tolerance: 3.465e+05\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.850e+08, tolerance: 3.465e+05\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "l1_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "alpha",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "ee3f20f8-93c0-4cdb-8feb-c0d29ca62615",
       "rows": [
        [
         "18",
         "0.8888888888888888",
         "0.5182068965517241",
         "3168.7411441949394"
        ],
        [
         "28",
         "0.8888888888888888",
         "1.0354137931034482",
         "3212.460342036518"
        ],
        [
         "17",
         "0.7777777777777777",
         "0.5182068965517241",
         "3212.772375144688"
        ],
        [
         "38",
         "0.8888888888888888",
         "1.5526206896551722",
         "3246.887473394909"
        ],
        [
         "16",
         "0.6666666666666666",
         "0.5182068965517241",
         "3247.398239225757"
        ],
        [
         "48",
         "0.8888888888888888",
         "2.0698275862068964",
         "3274.5628573686"
        ],
        [
         "27",
         "0.7777777777777777",
         "1.0354137931034482",
         "3275.0970085489025"
        ],
        [
         "15",
         "0.5555555555555556",
         "0.5182068965517241",
         "3275.43567922155"
        ],
        [
         "58",
         "0.8888888888888888",
         "2.5870344827586207",
         "3320.483623266369"
        ],
        [
         "14",
         "0.4444444444444444",
         "0.5182068965517241",
         "3321.4528693952598"
        ],
        [
         "26",
         "0.6666666666666666",
         "1.0354137931034482",
         "3377.932928972"
        ],
        [
         "37",
         "0.7777777777777777",
         "1.5526206896551722",
         "3377.9694804793485"
        ],
        [
         "13",
         "0.3333333333333333",
         "0.5182068965517241",
         "3378.1563461277406"
        ],
        [
         "68",
         "0.8888888888888888",
         "3.1042413793103445",
         "3378.3600266556978"
        ],
        [
         "12",
         "0.2222222222222222",
         "0.5182068965517241",
         "3435.596569300468"
        ],
        [
         "78",
         "0.8888888888888888",
         "3.6214482758620687",
         "3435.780504893305"
        ],
        [
         "25",
         "0.5555555555555556",
         "1.0354137931034482",
         "3477.9982083069212"
        ],
        [
         "47",
         "0.7777777777777777",
         "2.0698275862068964",
         "3478.047637296348"
        ],
        [
         "11",
         "0.1111111111111111",
         "0.5182068965517241",
         "3478.1901417848253"
        ],
        [
         "88",
         "0.8888888888888888",
         "4.138655172413793",
         "3478.3431273571528"
        ],
        [
         "36",
         "0.6666666666666666",
         "1.5526206896551722",
         "3510.0075900328425"
        ],
        [
         "10",
         "0.0",
         "0.5182068965517241",
         "3510.1812470405143"
        ],
        [
         "98",
         "0.8888888888888888",
         "4.655862068965518",
         "3510.333862451193"
        ],
        [
         "24",
         "0.4444444444444444",
         "1.0354137931034482",
         "3534.2025638155537"
        ],
        [
         "57",
         "0.7777777777777777",
         "2.5870344827586207",
         "3534.238757442661"
        ],
        [
         "108",
         "0.8888888888888888",
         "5.173068965517242",
         "3534.448365873974"
        ],
        [
         "118",
         "0.8888888888888888",
         "5.690275862068966",
         "3552.703106440923"
        ],
        [
         "133",
         "0.3333333333333333",
         "6.724689655172414",
         "3561.2775364485365"
        ],
        [
         "112",
         "0.2222222222222222",
         "5.690275862068966",
         "3561.2803808736394"
        ],
        [
         "101",
         "0.1111111111111111",
         "5.173068965517242",
         "3561.284879832741"
        ],
        [
         "164",
         "0.4444444444444444",
         "8.276310344827586",
         "3561.3341457658503"
        ],
        [
         "90",
         "0.0",
         "4.655862068965518",
         "3561.3366797882663"
        ],
        [
         "205",
         "0.5555555555555556",
         "10.345137931034483",
         "3561.388524495515"
        ],
        [
         "266",
         "0.6666666666666666",
         "13.448379310344826",
         "3561.3906898827186"
        ],
        [
         "195",
         "0.5555555555555556",
         "9.827931034482758",
         "3561.4321287491625"
        ],
        [
         "154",
         "0.4444444444444444",
         "7.759103448275862",
         "3561.4611176643443"
        ],
        [
         "276",
         "0.6666666666666666",
         "13.965586206896552",
         "3561.498717923651"
        ],
        [
         "256",
         "0.6666666666666666",
         "12.931172413793103",
         "3561.55628114368"
        ],
        [
         "80",
         "0.0",
         "4.138655172413793",
         "3561.845502245517"
        ],
        [
         "91",
         "0.1111111111111111",
         "4.655862068965518",
         "3561.854387107117"
        ],
        [
         "123",
         "0.3333333333333333",
         "6.2074827586206895",
         "3561.8769798217477"
        ],
        [
         "185",
         "0.5555555555555556",
         "9.310724137931034",
         "3561.925710795349"
        ],
        [
         "246",
         "0.6666666666666666",
         "12.413965517241378",
         "3562.001065512051"
        ],
        [
         "102",
         "0.2222222222222222",
         "5.173068965517242",
         "3562.319319931888"
        ],
        [
         "144",
         "0.4444444444444444",
         "7.241896551724138",
         "3562.358304085435"
        ],
        [
         "236",
         "0.6666666666666666",
         "11.896758620689655",
         "3562.7289556366113"
        ],
        [
         "175",
         "0.5555555555555556",
         "8.793517241379309",
         "3562.9538351501806"
        ],
        [
         "122",
         "0.2222222222222222",
         "6.2074827586206895",
         "3563.3615725199534"
        ],
        [
         "143",
         "0.3333333333333333",
         "7.241896551724138",
         "3563.366379060296"
        ],
        [
         "215",
         "0.5555555555555556",
         "10.862344827586206",
         "3563.40902588848"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 300
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1_ratio</th>\n",
       "      <th>alpha</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.518207</td>\n",
       "      <td>3168.741144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.035414</td>\n",
       "      <td>3212.460342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.518207</td>\n",
       "      <td>3212.772375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.552621</td>\n",
       "      <td>3246.887473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.518207</td>\n",
       "      <td>3247.398239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3829.393488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.448379</td>\n",
       "      <td>3833.511103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.965586</td>\n",
       "      <td>3852.397397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.482793</td>\n",
       "      <td>3871.315934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3890.244408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     l1_ratio      alpha        score\n",
       "18   0.888889   0.518207  3168.741144\n",
       "28   0.888889   1.035414  3212.460342\n",
       "17   0.777778   0.518207  3212.772375\n",
       "38   0.888889   1.552621  3246.887473\n",
       "16   0.666667   0.518207  3247.398239\n",
       "..        ...        ...          ...\n",
       "291  0.111111  15.000000  3829.393488\n",
       "260  0.000000  13.448379  3833.511103\n",
       "270  0.000000  13.965586  3852.397397\n",
       "280  0.000000  14.482793  3871.315934\n",
       "290  0.000000  15.000000  3890.244408\n",
       "\n",
       "[300 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alphas = [0.001, 0.01, 0.1, 1, 1.5, 2.5, 5,10]\n",
    "alphas = np.linspace(0.001, 15, 30)\n",
    "l1 = np.linspace(0,1,10)\n",
    "scores = []\n",
    "\n",
    "for a in alphas:\n",
    "    for r in l1:\n",
    "        elastic_net = ElasticNet(alpha=a, l1_ratio=r)\n",
    "        elastic_net.fit(x_train, y_train)\n",
    "        y_pred = elastic_net.predict(x_test)\n",
    "        scores.append([r,a,mean_absolute_error(y_test, y_pred)])\n",
    "\n",
    "df_Scores = pd.DataFrame(scores, columns = ['l1_ratio', 'alpha', 'score'])\n",
    "df_Scores.sort_values('score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a5a500",
   "metadata": {},
   "source": [
    "Housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b3113e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "price",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lotsize",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "bedrooms",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "bathrms",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "stories",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "driveway",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "recroom",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "fullbase",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "gashw",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "airco",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "garagepl",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "prefarea",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "6326e1b1-5310-464f-acf5-ae985d3ea9a5",
       "rows": [
        [
         "0",
         "42000.0",
         "5850",
         "3",
         "1",
         "2",
         "yes",
         "no",
         "yes",
         "no",
         "no",
         "1",
         "no"
        ],
        [
         "1",
         "38500.0",
         "4000",
         "2",
         "1",
         "1",
         "yes",
         "no",
         "no",
         "no",
         "no",
         "0",
         "no"
        ],
        [
         "2",
         "49500.0",
         "3060",
         "3",
         "1",
         "1",
         "yes",
         "no",
         "no",
         "no",
         "no",
         "0",
         "no"
        ],
        [
         "3",
         "60500.0",
         "6650",
         "3",
         "1",
         "2",
         "yes",
         "yes",
         "no",
         "no",
         "no",
         "0",
         "no"
        ],
        [
         "4",
         "61000.0",
         "6360",
         "2",
         "1",
         "1",
         "yes",
         "no",
         "no",
         "no",
         "no",
         "0",
         "no"
        ],
        [
         "5",
         "66000.0",
         "4160",
         "3",
         "1",
         "1",
         "yes",
         "yes",
         "yes",
         "no",
         "yes",
         "0",
         "no"
        ],
        [
         "6",
         "66000.0",
         "3880",
         "3",
         "2",
         "2",
         "yes",
         "no",
         "yes",
         "no",
         "no",
         "2",
         "no"
        ],
        [
         "7",
         "69000.0",
         "4160",
         "3",
         "1",
         "3",
         "yes",
         "no",
         "no",
         "no",
         "no",
         "0",
         "no"
        ],
        [
         "8",
         "83800.0",
         "4800",
         "3",
         "1",
         "1",
         "yes",
         "yes",
         "yes",
         "no",
         "no",
         "0",
         "no"
        ],
        [
         "9",
         "88500.0",
         "5500",
         "3",
         "2",
         "4",
         "yes",
         "yes",
         "no",
         "no",
         "yes",
         "1",
         "no"
        ],
        [
         "10",
         "90000.0",
         "7200",
         "3",
         "2",
         "1",
         "yes",
         "no",
         "yes",
         "no",
         "yes",
         "3",
         "no"
        ],
        [
         "11",
         "30500.0",
         "3000",
         "2",
         "1",
         "1",
         "no",
         "no",
         "no",
         "no",
         "no",
         "0",
         "no"
        ],
        [
         "12",
         "27000.0",
         "1700",
         "3",
         "1",
         "2",
         "yes",
         "no",
         "no",
         "no",
         "no",
         "0",
         "no"
        ],
        [
         "13",
         "36000.0",
         "2880",
         "3",
         "1",
         "1",
         "no",
         "no",
         "no",
         "no",
         "no",
         "0",
         "no"
        ],
        [
         "14",
         "37000.0",
         "3600",
         "2",
         "1",
         "1",
         "yes",
         "no",
         "no",
         "no",
         "no",
         "0",
         "no"
        ],
        [
         "15",
         "37900.0",
         "3185",
         "2",
         "1",
         "1",
         "yes",
         "no",
         "no",
         "no",
         "yes",
         "0",
         "no"
        ],
        [
         "16",
         "40500.0",
         "3300",
         "3",
         "1",
         "2",
         "no",
         "no",
         "no",
         "no",
         "no",
         "1",
         "no"
        ],
        [
         "17",
         "40750.0",
         "5200",
         "4",
         "1",
         "3",
         "yes",
         "no",
         "no",
         "no",
         "no",
         "0",
         "no"
        ],
        [
         "18",
         "45000.0",
         "3450",
         "1",
         "1",
         "1",
         "yes",
         "no",
         "no",
         "no",
         "no",
         "0",
         "no"
        ],
        [
         "19",
         "45000.0",
         "3986",
         "2",
         "2",
         "1",
         "no",
         "yes",
         "yes",
         "no",
         "no",
         "1",
         "no"
        ],
        [
         "20",
         "48500.0",
         "4785",
         "3",
         "1",
         "2",
         "yes",
         "yes",
         "yes",
         "no",
         "yes",
         "1",
         "no"
        ],
        [
         "21",
         "65900.0",
         "4510",
         "4",
         "2",
         "2",
         "yes",
         "no",
         "yes",
         "no",
         "no",
         "0",
         "no"
        ],
        [
         "22",
         "37900.0",
         "4000",
         "3",
         "1",
         "2",
         "yes",
         "no",
         "no",
         "no",
         "yes",
         "0",
         "no"
        ],
        [
         "23",
         "38000.0",
         "3934",
         "2",
         "1",
         "1",
         "yes",
         "no",
         "no",
         "no",
         "no",
         "0",
         "no"
        ],
        [
         "24",
         "42000.0",
         "4960",
         "2",
         "1",
         "1",
         "yes",
         "no",
         "no",
         "no",
         "no",
         "0",
         "no"
        ],
        [
         "25",
         "42300.0",
         "3000",
         "2",
         "1",
         "2",
         "yes",
         "no",
         "no",
         "no",
         "no",
         "0",
         "no"
        ],
        [
         "26",
         "43500.0",
         "3800",
         "2",
         "1",
         "1",
         "yes",
         "no",
         "no",
         "no",
         "no",
         "0",
         "no"
        ],
        [
         "27",
         "44000.0",
         "4960",
         "2",
         "1",
         "1",
         "yes",
         "no",
         "yes",
         "no",
         "yes",
         "0",
         "no"
        ],
        [
         "28",
         "44500.0",
         "3000",
         "3",
         "1",
         "1",
         "no",
         "no",
         "no",
         "no",
         "yes",
         "0",
         "no"
        ],
        [
         "29",
         "44900.0",
         "4500",
         "3",
         "1",
         "2",
         "yes",
         "no",
         "no",
         "no",
         "yes",
         "0",
         "no"
        ],
        [
         "30",
         "45000.0",
         "3500",
         "2",
         "1",
         "1",
         "no",
         "no",
         "yes",
         "no",
         "no",
         "0",
         "no"
        ],
        [
         "31",
         "48000.0",
         "3500",
         "4",
         "1",
         "2",
         "yes",
         "no",
         "no",
         "no",
         "yes",
         "2",
         "no"
        ],
        [
         "32",
         "49000.0",
         "4000",
         "2",
         "1",
         "1",
         "yes",
         "no",
         "no",
         "no",
         "no",
         "0",
         "no"
        ],
        [
         "33",
         "51500.0",
         "4500",
         "2",
         "1",
         "1",
         "yes",
         "no",
         "no",
         "no",
         "no",
         "0",
         "no"
        ],
        [
         "34",
         "61000.0",
         "6360",
         "2",
         "1",
         "2",
         "yes",
         "no",
         "no",
         "no",
         "no",
         "0",
         "no"
        ],
        [
         "35",
         "61000.0",
         "4500",
         "2",
         "1",
         "1",
         "yes",
         "no",
         "no",
         "no",
         "yes",
         "2",
         "no"
        ],
        [
         "36",
         "61700.0",
         "4032",
         "2",
         "1",
         "1",
         "yes",
         "no",
         "yes",
         "no",
         "no",
         "0",
         "no"
        ],
        [
         "37",
         "67000.0",
         "5170",
         "3",
         "1",
         "4",
         "yes",
         "no",
         "no",
         "no",
         "yes",
         "0",
         "no"
        ],
        [
         "38",
         "82000.0",
         "5400",
         "4",
         "2",
         "2",
         "yes",
         "no",
         "no",
         "no",
         "yes",
         "2",
         "no"
        ],
        [
         "39",
         "54500.0",
         "3150",
         "2",
         "2",
         "1",
         "no",
         "no",
         "yes",
         "no",
         "no",
         "0",
         "no"
        ],
        [
         "40",
         "66500.0",
         "3745",
         "3",
         "1",
         "2",
         "yes",
         "no",
         "yes",
         "no",
         "no",
         "0",
         "no"
        ],
        [
         "41",
         "70000.0",
         "4520",
         "3",
         "1",
         "2",
         "yes",
         "no",
         "yes",
         "no",
         "yes",
         "0",
         "no"
        ],
        [
         "42",
         "82000.0",
         "4640",
         "4",
         "1",
         "2",
         "yes",
         "no",
         "no",
         "no",
         "no",
         "1",
         "no"
        ],
        [
         "43",
         "92000.0",
         "8580",
         "5",
         "3",
         "2",
         "yes",
         "no",
         "no",
         "no",
         "no",
         "2",
         "no"
        ],
        [
         "44",
         "38000.0",
         "2000",
         "2",
         "1",
         "2",
         "yes",
         "no",
         "no",
         "no",
         "no",
         "0",
         "no"
        ],
        [
         "45",
         "44000.0",
         "2160",
         "3",
         "1",
         "2",
         "no",
         "no",
         "yes",
         "no",
         "no",
         "0",
         "no"
        ],
        [
         "46",
         "41000.0",
         "3040",
         "2",
         "1",
         "1",
         "no",
         "no",
         "no",
         "no",
         "no",
         "0",
         "no"
        ],
        [
         "47",
         "43000.0",
         "3090",
         "3",
         "1",
         "2",
         "no",
         "no",
         "no",
         "no",
         "no",
         "0",
         "no"
        ],
        [
         "48",
         "48000.0",
         "4960",
         "4",
         "1",
         "3",
         "no",
         "no",
         "no",
         "no",
         "no",
         "0",
         "no"
        ],
        [
         "49",
         "54800.0",
         "3350",
         "3",
         "1",
         "2",
         "yes",
         "no",
         "no",
         "no",
         "no",
         "0",
         "no"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 546
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>lotsize</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrms</th>\n",
       "      <th>stories</th>\n",
       "      <th>driveway</th>\n",
       "      <th>recroom</th>\n",
       "      <th>fullbase</th>\n",
       "      <th>gashw</th>\n",
       "      <th>airco</th>\n",
       "      <th>garagepl</th>\n",
       "      <th>prefarea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42000.0</td>\n",
       "      <td>5850</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38500.0</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49500.0</td>\n",
       "      <td>3060</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60500.0</td>\n",
       "      <td>6650</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61000.0</td>\n",
       "      <td>6360</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>91500.0</td>\n",
       "      <td>4800</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>94000.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>103000.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>105000.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>105000.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>546 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        price  lotsize  bedrooms  bathrms  stories driveway recroom fullbase  \\\n",
       "0     42000.0     5850         3        1        2      yes      no      yes   \n",
       "1     38500.0     4000         2        1        1      yes      no       no   \n",
       "2     49500.0     3060         3        1        1      yes      no       no   \n",
       "3     60500.0     6650         3        1        2      yes     yes       no   \n",
       "4     61000.0     6360         2        1        1      yes      no       no   \n",
       "..        ...      ...       ...      ...      ...      ...     ...      ...   \n",
       "541   91500.0     4800         3        2        4      yes     yes       no   \n",
       "542   94000.0     6000         3        2        4      yes      no       no   \n",
       "543  103000.0     6000         3        2        4      yes     yes       no   \n",
       "544  105000.0     6000         3        2        2      yes     yes       no   \n",
       "545  105000.0     6000         3        1        2      yes      no       no   \n",
       "\n",
       "    gashw airco  garagepl prefarea  \n",
       "0      no    no         1       no  \n",
       "1      no    no         0       no  \n",
       "2      no    no         0       no  \n",
       "3      no    no         0       no  \n",
       "4      no    no         0       no  \n",
       "..    ...   ...       ...      ...  \n",
       "541    no   yes         0       no  \n",
       "542    no   yes         0       no  \n",
       "543    no   yes         1       no  \n",
       "544    no   yes         1       no  \n",
       "545    no   yes         1       no  \n",
       "\n",
       "[546 rows x 12 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = pd.read_csv('../datasets/Housing.csv')\n",
    "housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0ba96a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = housing.drop('price', axis=1) , housing['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad2a6eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test, y_train, y_test = train_test_split(x,y,random_state=25, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7fafb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(drop = 'first', sparse_output = False).set_output(transform = 'pandas')\n",
    "col_trnf = ColumnTransformer([('OHE', ohe, make_column_selector(dtype_include = object))],\n",
    "                             remainder = 'passthrough',\n",
    "                             verbose_feature_names_out=False)\n",
    "col_trnf = col_trnf.set_output(transform = 'pandas')\n",
    "x = col_trnf.fit_transform(x)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.3, random_state = 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6af3050d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.212e+10, tolerance: 2.625e+07\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.651e+10, tolerance: 2.625e+07\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.353e+10, tolerance: 2.625e+07\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.724e+10, tolerance: 2.625e+07\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.956e+10, tolerance: 2.625e+07\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.116e+10, tolerance: 2.625e+07\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.233e+10, tolerance: 2.625e+07\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.322e+10, tolerance: 2.625e+07\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.393e+10, tolerance: 2.625e+07\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.450e+10, tolerance: 2.625e+07\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.498e+10, tolerance: 2.625e+07\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.537e+10, tolerance: 2.625e+07\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.571e+10, tolerance: 2.625e+07\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.601e+10, tolerance: 2.625e+07\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.626e+10, tolerance: 2.625e+07\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.648e+10, tolerance: 2.625e+07\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.668e+10, tolerance: 2.625e+07\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.686e+10, tolerance: 2.625e+07\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.702e+10, tolerance: 2.625e+07\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.716e+10, tolerance: 2.625e+07\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.729e+10, tolerance: 2.625e+07\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.741e+10, tolerance: 2.625e+07\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.752e+10, tolerance: 2.625e+07\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.762e+10, tolerance: 2.625e+07\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.771e+10, tolerance: 2.625e+07\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.780e+10, tolerance: 2.625e+07\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.788e+10, tolerance: 2.625e+07\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.795e+10, tolerance: 2.625e+07\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.802e+10, tolerance: 2.625e+07\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\dbda.STUDENTSDC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.808e+10, tolerance: 2.625e+07\n",
      "Linear regression models with a zero l1 penalization strength are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "l1_ratio",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "alpha",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "f7e119f2-5fe5-4bbe-914f-d4ec559e2e74",
       "rows": [
        [
         "299",
         "1.0",
         "15.0",
         "11591.41467203429"
        ],
        [
         "289",
         "1.0",
         "14.482793103448275",
         "11591.743776664129"
        ],
        [
         "279",
         "1.0",
         "13.965586206896552",
         "11592.07288129397"
        ],
        [
         "269",
         "1.0",
         "13.448379310344826",
         "11592.401985923812"
        ],
        [
         "0",
         "0.0",
         "0.001",
         "11592.600888066663"
        ],
        [
         "259",
         "1.0",
         "12.931172413793103",
         "11592.731090553656"
        ],
        [
         "249",
         "1.0",
         "12.413965517241378",
         "11593.060195183494"
        ],
        [
         "239",
         "1.0",
         "11.896758620689655",
         "11593.389299813338"
        ],
        [
         "1",
         "0.1111111111111111",
         "0.001",
         "11593.51553886643"
        ],
        [
         "229",
         "1.0",
         "11.379551724137931",
         "11593.71840444318"
        ],
        [
         "219",
         "1.0",
         "10.862344827586206",
         "11594.047509073022"
        ],
        [
         "209",
         "1.0",
         "10.345137931034483",
         "11594.376613702862"
        ],
        [
         "2",
         "0.2222222222222222",
         "0.001",
         "11594.433151369829"
        ],
        [
         "199",
         "1.0",
         "9.827931034482758",
         "11594.705718332703"
        ],
        [
         "189",
         "1.0",
         "9.310724137931034",
         "11595.034822962545"
        ],
        [
         "3",
         "0.3333333333333333",
         "0.001",
         "11595.353747940826"
        ],
        [
         "179",
         "1.0",
         "8.793517241379309",
         "11595.363927592385"
        ],
        [
         "169",
         "1.0",
         "8.276310344827586",
         "11595.693032222229"
        ],
        [
         "159",
         "1.0",
         "7.759103448275862",
         "11596.022136852069"
        ],
        [
         "4",
         "0.4444444444444444",
         "0.001",
         "11596.277344883107"
        ],
        [
         "149",
         "1.0",
         "7.241896551724138",
         "11596.35124148191"
        ],
        [
         "139",
         "1.0",
         "6.724689655172414",
         "11596.680346111752"
        ],
        [
         "129",
         "1.0",
         "6.2074827586206895",
         "11597.009450741594"
        ],
        [
         "5",
         "0.5555555555555556",
         "0.001",
         "11597.203964068685"
        ],
        [
         "119",
         "1.0",
         "5.690275862068966",
         "11597.338555371436"
        ],
        [
         "109",
         "1.0",
         "5.173068965517242",
         "11597.667660001278"
        ],
        [
         "99",
         "1.0",
         "4.655862068965518",
         "11597.996764631118"
        ],
        [
         "6",
         "0.6666666666666666",
         "0.001",
         "11598.13362579031"
        ],
        [
         "89",
         "1.0",
         "4.138655172413793",
         "11598.32586926096"
        ],
        [
         "79",
         "1.0",
         "3.6214482758620687",
         "11598.654973890803"
        ],
        [
         "69",
         "1.0",
         "3.1042413793103445",
         "11598.984078520645"
        ],
        [
         "7",
         "0.7777777777777777",
         "0.001",
         "11599.066350545363"
        ],
        [
         "59",
         "1.0",
         "2.5870344827586207",
         "11599.313183150483"
        ],
        [
         "49",
         "1.0",
         "2.0698275862068964",
         "11599.642287780327"
        ],
        [
         "39",
         "1.0",
         "1.5526206896551722",
         "11599.955817642269"
        ],
        [
         "8",
         "0.8888888888888888",
         "0.001",
         "11600.002164821019"
        ],
        [
         "29",
         "1.0",
         "1.0354137931034482",
         "11600.2849231076"
        ],
        [
         "19",
         "1.0",
         "0.5182068965517241",
         "11600.61402857293"
        ],
        [
         "9",
         "1.0",
         "0.001",
         "11600.941078046237"
        ],
        [
         "18",
         "0.8888888888888888",
         "0.5182068965517241",
         "11679.364823504224"
        ],
        [
         "28",
         "0.8888888888888888",
         "1.0354137931034482",
         "12015.799584223769"
        ],
        [
         "17",
         "0.7777777777777777",
         "0.5182068965517241",
         "12015.925449546883"
        ],
        [
         "38",
         "0.8888888888888888",
         "1.5526206896551722",
         "12328.374006480095"
        ],
        [
         "16",
         "0.6666666666666666",
         "0.5182068965517241",
         "12328.496974206339"
        ],
        [
         "27",
         "0.7777777777777777",
         "1.0354137931034482",
         "12614.910954383196"
        ],
        [
         "48",
         "0.8888888888888888",
         "2.0698275862068964",
         "12615.43478817664"
        ],
        [
         "15",
         "0.5555555555555556",
         "0.5182068965517241",
         "12615.441687474558"
        ],
        [
         "14",
         "0.4444444444444444",
         "0.5182068965517241",
         "12870.470691289656"
        ],
        [
         "58",
         "0.8888888888888888",
         "2.5870344827586207",
         "12870.661109926867"
        ],
        [
         "26",
         "0.6666666666666666",
         "1.0354137931034482",
         "13113.316965798367"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 300
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l1_ratio</th>\n",
       "      <th>alpha</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>11591.414672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.482793</td>\n",
       "      <td>11591.743777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.965586</td>\n",
       "      <td>11592.072881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.448379</td>\n",
       "      <td>11592.401986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>11592.600888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>17790.206876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.448379</td>\n",
       "      <td>17794.425919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.965586</td>\n",
       "      <td>17813.423794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.482793</td>\n",
       "      <td>17831.138533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>17847.695921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     l1_ratio      alpha         score\n",
       "299  1.000000  15.000000  11591.414672\n",
       "289  1.000000  14.482793  11591.743777\n",
       "279  1.000000  13.965586  11592.072881\n",
       "269  1.000000  13.448379  11592.401986\n",
       "0    0.000000   0.001000  11592.600888\n",
       "..        ...        ...           ...\n",
       "291  0.111111  15.000000  17790.206876\n",
       "260  0.000000  13.448379  17794.425919\n",
       "270  0.000000  13.965586  17813.423794\n",
       "280  0.000000  14.482793  17831.138533\n",
       "290  0.000000  15.000000  17847.695921\n",
       "\n",
       "[300 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alphas = [0.001, 0.01, 0.1, 1, 1.5, 2.5, 5,10]\n",
    "alphas = np.linspace(0.001, 15, 30)\n",
    "l1 = np.linspace(0,1,10)\n",
    "scores = []\n",
    "\n",
    "for a in alphas:\n",
    "    for r in l1:\n",
    "        elastic_net = ElasticNet(alpha=a, l1_ratio=r)\n",
    "        elastic_net.fit(x_train, y_train)\n",
    "        y_pred = elastic_net.predict(x_test)\n",
    "        scores.append([r,a,mean_absolute_error(y_test, y_pred)])\n",
    "\n",
    "df_Scores = pd.DataFrame(scores, columns = ['l1_ratio','alpha', 'score'])\n",
    "df_Scores.sort_values('score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24ff70f",
   "metadata": {},
   "source": [
    "Exp_Salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c90ca26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Salary",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Years_Previous_Experience",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Years Employed",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Years_Education",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Gender",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Department",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Number_Supervised",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "1bfccf9e-f5db-45e4-a97d-624c300dd239",
       "rows": [
        [
         "0",
         "32782",
         "1",
         "0",
         "7",
         "Male",
         "A",
         "0"
        ],
        [
         "1",
         "32920",
         "3",
         "15",
         "9",
         "Female",
         "A",
         "4"
        ],
        [
         "2",
         "29548",
         "6",
         "5",
         "1",
         "Male",
         "A",
         "0"
        ],
        [
         "3",
         "39828",
         "6",
         "18",
         "5",
         "Female",
         "A",
         "5"
        ],
        [
         "4",
         "31528",
         "11",
         "3",
         "3",
         "Male",
         "A",
         "6"
        ],
        [
         "5",
         "38985",
         "7",
         "18",
         "9",
         "Male",
         "A",
         "5"
        ],
        [
         "6",
         "41889",
         "16",
         "22",
         "7",
         "Male",
         "A",
         "7"
        ],
        [
         "7",
         "38791",
         "4",
         "21",
         "5",
         "Male",
         "A",
         "9"
        ],
        [
         "8",
         "28985",
         "1",
         "0",
         "4",
         "Female",
         "A",
         "4"
        ],
        [
         "9",
         "24749",
         "2",
         "6",
         "0",
         "Female",
         "A",
         "1"
        ],
        [
         "10",
         "35467",
         "6",
         "3",
         "6",
         "Female",
         "B",
         "3"
        ],
        [
         "11",
         "35468",
         "5",
         "9",
         "4",
         "Female",
         "B",
         "5"
        ],
        [
         "12",
         "29876",
         "0",
         "2",
         "3",
         "Female",
         "B",
         "5"
        ],
        [
         "13",
         "43674",
         "9",
         "6",
         "4",
         "Male",
         "B",
         "2"
        ],
        [
         "14",
         "36431",
         "4",
         "9",
         "4",
         "Female",
         "B",
         "2"
        ],
        [
         "15",
         "26578",
         "6",
         "0",
         "2",
         "Female",
         "B",
         "2"
        ],
        [
         "16",
         "36571",
         "1",
         "6",
         "4",
         "Male",
         "B",
         "2"
        ],
        [
         "17",
         "56326",
         "3",
         "12",
         "8",
         "Male",
         "B",
         "6"
        ],
        [
         "18",
         "23654",
         "0",
         "0",
         "0",
         "Female",
         "C",
         "2"
        ],
        [
         "19",
         "36578",
         "4",
         "4",
         "8",
         "Male",
         "C",
         "8"
        ],
        [
         "20",
         "37548",
         "9",
         "19",
         "4",
         "Male",
         "C",
         "6"
        ],
        [
         "21",
         "53234",
         "0",
         "25",
         "6",
         "Male",
         "C",
         "3"
        ],
        [
         "22",
         "54679",
         "3",
         "20",
         "6",
         "Female",
         "C",
         "4"
        ],
        [
         "23",
         "47536",
         "5",
         "15",
         "6",
         "Male",
         "C",
         "4"
        ],
        [
         "24",
         "31425",
         "6",
         "7",
         "5",
         "Female",
         "C",
         "6"
        ],
        [
         "25",
         "65487",
         "0",
         "27",
         "12",
         "Female",
         "D",
         "44"
        ],
        [
         "26",
         "46184",
         "3",
         "20",
         "4",
         "Male",
         "D",
         "1"
        ],
        [
         "27",
         "54899",
         "5",
         "12",
         "8",
         "Female",
         "D",
         "0"
        ],
        [
         "28",
         "34869",
         "5",
         "7",
         "4",
         "Female",
         "D",
         "1"
        ],
        [
         "29",
         "35487",
         "2",
         "8",
         "2",
         "Female",
         "D",
         "2"
        ],
        [
         "30",
         "26548",
         "1",
         "5",
         "0",
         "Male",
         "D",
         "2"
        ],
        [
         "31",
         "34231",
         "2",
         "6",
         "6",
         "Male",
         "D",
         "3"
        ],
        [
         "32",
         "39331",
         "3",
         "9",
         "6",
         "Female",
         "D",
         "1"
        ],
        [
         "33",
         "36512",
         "6",
         "6",
         "4",
         "Female",
         "D",
         "2"
        ],
        [
         "34",
         "68425",
         "2",
         "25",
         "12",
         "Male",
         "D",
         "1"
        ],
        [
         "35",
         "36487",
         "5",
         "6",
         "2",
         "Male",
         "D",
         "3"
        ],
        [
         "36",
         "34632",
         "4",
         "5",
         "4",
         "Male",
         "D",
         "0"
        ],
        [
         "37",
         "46211",
         "5",
         "14",
         "6",
         "Female",
         "D",
         "5"
        ],
        [
         "38",
         "51698",
         "6",
         "18",
         "6",
         "Male",
         "D",
         "1"
        ],
        [
         "39",
         "69246",
         "3",
         "22",
         "10",
         "Male",
         "D",
         "45"
        ],
        [
         "40",
         "48695",
         "19",
         "6",
         "8",
         "Male",
         "D",
         "40"
        ],
        [
         "41",
         "34987",
         "6",
         "9",
         "2",
         "Female",
         "D",
         "3"
        ],
        [
         "42",
         "35631",
         "4",
         "6",
         "4",
         "Male",
         "D",
         "2"
        ],
        [
         "43",
         "39743",
         "6",
         "9",
         "5",
         "Female",
         "D",
         "1"
        ],
        [
         "44",
         "41255",
         "4",
         "9",
         "6",
         "Male",
         "D",
         "4"
        ],
        [
         "45",
         "26452",
         "3",
         "1",
         "2",
         "Female",
         "D",
         "0"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 46
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary</th>\n",
       "      <th>Years_Previous_Experience</th>\n",
       "      <th>Years Employed</th>\n",
       "      <th>Years_Education</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Department</th>\n",
       "      <th>Number_Supervised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32782</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>Male</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32920</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>Female</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29548</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39828</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31528</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>A</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>38985</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>Male</td>\n",
       "      <td>A</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41889</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>Male</td>\n",
       "      <td>A</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>38791</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>Male</td>\n",
       "      <td>A</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>28985</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Female</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24749</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>35467</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>Female</td>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>35468</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>Female</td>\n",
       "      <td>B</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>29876</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>B</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>43674</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>36431</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>Female</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>26578</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>36571</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>56326</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>Male</td>\n",
       "      <td>B</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>23654</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>36578</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>Male</td>\n",
       "      <td>C</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>37548</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>C</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>53234</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>Male</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>54679</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>Female</td>\n",
       "      <td>C</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>47536</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>Male</td>\n",
       "      <td>C</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>31425</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>C</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>65487</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>Female</td>\n",
       "      <td>D</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>46184</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>54899</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>Female</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>34869</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>Female</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>35487</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>26548</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>34231</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>Male</td>\n",
       "      <td>D</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>39331</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>Female</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>36512</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>Female</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>68425</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>Male</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36487</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>D</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>34632</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>46211</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>Female</td>\n",
       "      <td>D</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>51698</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>Male</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>69246</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>Male</td>\n",
       "      <td>D</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>48695</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>Male</td>\n",
       "      <td>D</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>34987</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>D</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>35631</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>39743</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>41255</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>Male</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>26452</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Salary  Years_Previous_Experience  Years Employed  Years_Education  \\\n",
       "0    32782                          1               0                7   \n",
       "1    32920                          3              15                9   \n",
       "2    29548                          6               5                1   \n",
       "3    39828                          6              18                5   \n",
       "4    31528                         11               3                3   \n",
       "5    38985                          7              18                9   \n",
       "6    41889                         16              22                7   \n",
       "7    38791                          4              21                5   \n",
       "8    28985                          1               0                4   \n",
       "9    24749                          2               6                0   \n",
       "10   35467                          6               3                6   \n",
       "11   35468                          5               9                4   \n",
       "12   29876                          0               2                3   \n",
       "13   43674                          9               6                4   \n",
       "14   36431                          4               9                4   \n",
       "15   26578                          6               0                2   \n",
       "16   36571                          1               6                4   \n",
       "17   56326                          3              12                8   \n",
       "18   23654                          0               0                0   \n",
       "19   36578                          4               4                8   \n",
       "20   37548                          9              19                4   \n",
       "21   53234                          0              25                6   \n",
       "22   54679                          3              20                6   \n",
       "23   47536                          5              15                6   \n",
       "24   31425                          6               7                5   \n",
       "25   65487                          0              27               12   \n",
       "26   46184                          3              20                4   \n",
       "27   54899                          5              12                8   \n",
       "28   34869                          5               7                4   \n",
       "29   35487                          2               8                2   \n",
       "30   26548                          1               5                0   \n",
       "31   34231                          2               6                6   \n",
       "32   39331                          3               9                6   \n",
       "33   36512                          6               6                4   \n",
       "34   68425                          2              25               12   \n",
       "35   36487                          5               6                2   \n",
       "36   34632                          4               5                4   \n",
       "37   46211                          5              14                6   \n",
       "38   51698                          6              18                6   \n",
       "39   69246                          3              22               10   \n",
       "40   48695                         19               6                8   \n",
       "41   34987                          6               9                2   \n",
       "42   35631                          4               6                4   \n",
       "43   39743                          6               9                5   \n",
       "44   41255                          4               9                6   \n",
       "45   26452                          3               1                2   \n",
       "\n",
       "    Gender Department  Number_Supervised  \n",
       "0     Male          A                  0  \n",
       "1   Female          A                  4  \n",
       "2     Male          A                  0  \n",
       "3   Female          A                  5  \n",
       "4     Male          A                  6  \n",
       "5     Male          A                  5  \n",
       "6     Male          A                  7  \n",
       "7     Male          A                  9  \n",
       "8   Female          A                  4  \n",
       "9   Female          A                  1  \n",
       "10  Female          B                  3  \n",
       "11  Female          B                  5  \n",
       "12  Female          B                  5  \n",
       "13    Male          B                  2  \n",
       "14  Female          B                  2  \n",
       "15  Female          B                  2  \n",
       "16    Male          B                  2  \n",
       "17    Male          B                  6  \n",
       "18  Female          C                  2  \n",
       "19    Male          C                  8  \n",
       "20    Male          C                  6  \n",
       "21    Male          C                  3  \n",
       "22  Female          C                  4  \n",
       "23    Male          C                  4  \n",
       "24  Female          C                  6  \n",
       "25  Female          D                 44  \n",
       "26    Male          D                  1  \n",
       "27  Female          D                  0  \n",
       "28  Female          D                  1  \n",
       "29  Female          D                  2  \n",
       "30    Male          D                  2  \n",
       "31    Male          D                  3  \n",
       "32  Female          D                  1  \n",
       "33  Female          D                  2  \n",
       "34    Male          D                  1  \n",
       "35    Male          D                  3  \n",
       "36    Male          D                  0  \n",
       "37  Female          D                  5  \n",
       "38    Male          D                  1  \n",
       "39    Male          D                 45  \n",
       "40    Male          D                 40  \n",
       "41  Female          D                  3  \n",
       "42    Male          D                  2  \n",
       "43  Female          D                  1  \n",
       "44    Male          D                  4  \n",
       "45  Female          D                  0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sals = pd.read_csv('../datasets/Exp_Salaries.csv')\n",
    "sals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ababb882",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = sals.drop('Salary', axis = 1),sals['Salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57f0a157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "alphas",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "mean_absolute_error",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "699039bd-247d-45d6-ac00-d6af73a7b41b",
       "rows": [
        [
         "29",
         "15.0",
         "3780.9705482188187"
        ],
        [
         "28",
         "14.482793103448275",
         "3774.3042616370794"
        ],
        [
         "27",
         "13.965586206896552",
         "3767.3788121550783"
        ],
        [
         "26",
         "13.448379310344826",
         "3760.171238783271"
        ],
        [
         "25",
         "12.931172413793103",
         "3752.657316830325"
        ],
        [
         "24",
         "12.413965517241378",
         "3744.8097736466407"
        ],
        [
         "23",
         "11.896758620689655",
         "3736.597762908977"
        ],
        [
         "22",
         "11.379551724137931",
         "3727.986219434675"
        ],
        [
         "21",
         "10.862344827586206",
         "3718.935059934562"
        ],
        [
         "20",
         "10.345137931034483",
         "3709.397172896417"
        ],
        [
         "19",
         "9.827931034482758",
         "3699.321166245568"
        ],
        [
         "18",
         "9.310724137931034",
         "3688.6437900308515"
        ],
        [
         "17",
         "8.793517241379309",
         "3677.291747869792"
        ],
        [
         "16",
         "8.276310344827586",
         "3665.177949870494"
        ],
        [
         "15",
         "7.759103448275862",
         "3652.1971742050655"
        ],
        [
         "14",
         "7.241896551724138",
         "3638.2234077983703"
        ],
        [
         "13",
         "6.724689655172414",
         "3623.099040604302"
        ],
        [
         "12",
         "6.2074827586206895",
         "3606.6270592718906"
        ],
        [
         "11",
         "5.690275862068966",
         "3588.5550742672945"
        ],
        [
         "10",
         "5.173068965517242",
         "3568.553636657466"
        ],
        [
         "9",
         "4.655862068965518",
         "3546.178007129129"
        ],
        [
         "8",
         "4.138655172413793",
         "3520.80953007196"
        ],
        [
         "7",
         "3.6214482758620687",
         "3501.6481393812683"
        ],
        [
         "6",
         "3.1042413793103445",
         "3479.483210222378"
        ],
        [
         "5",
         "2.5870344827586207",
         "3454.789341900877"
        ],
        [
         "4",
         "2.0698275862068964",
         "3437.646537296548"
        ],
        [
         "3",
         "1.5526206896551722",
         "3412.3823917680015"
        ],
        [
         "2",
         "1.0354137931034482",
         "3359.0258875259065"
        ],
        [
         "1",
         "0.5182068965517241",
         "3221.210532693348"
        ],
        [
         "0",
         "0.001",
         "3036.1353521459287"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 30
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alphas</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>3780.970548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>14.482793</td>\n",
       "      <td>3774.304262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13.965586</td>\n",
       "      <td>3767.378812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13.448379</td>\n",
       "      <td>3760.171239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12.931172</td>\n",
       "      <td>3752.657317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12.413966</td>\n",
       "      <td>3744.809774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>11.896759</td>\n",
       "      <td>3736.597763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11.379552</td>\n",
       "      <td>3727.986219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10.862345</td>\n",
       "      <td>3718.935060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10.345138</td>\n",
       "      <td>3709.397173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9.827931</td>\n",
       "      <td>3699.321166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.310724</td>\n",
       "      <td>3688.643790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8.793517</td>\n",
       "      <td>3677.291748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8.276310</td>\n",
       "      <td>3665.177950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.759103</td>\n",
       "      <td>3652.197174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.241897</td>\n",
       "      <td>3638.223408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.724690</td>\n",
       "      <td>3623.099041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.207483</td>\n",
       "      <td>3606.627059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.690276</td>\n",
       "      <td>3588.555074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.173069</td>\n",
       "      <td>3568.553637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.655862</td>\n",
       "      <td>3546.178007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.138655</td>\n",
       "      <td>3520.809530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.621448</td>\n",
       "      <td>3501.648139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.104241</td>\n",
       "      <td>3479.483210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.587034</td>\n",
       "      <td>3454.789342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.069828</td>\n",
       "      <td>3437.646537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.552621</td>\n",
       "      <td>3412.382392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.035414</td>\n",
       "      <td>3359.025888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.518207</td>\n",
       "      <td>3221.210533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>3036.135352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       alphas  mean_absolute_error\n",
       "29  15.000000          3780.970548\n",
       "28  14.482793          3774.304262\n",
       "27  13.965586          3767.378812\n",
       "26  13.448379          3760.171239\n",
       "25  12.931172          3752.657317\n",
       "24  12.413966          3744.809774\n",
       "23  11.896759          3736.597763\n",
       "22  11.379552          3727.986219\n",
       "21  10.862345          3718.935060\n",
       "20  10.345138          3709.397173\n",
       "19   9.827931          3699.321166\n",
       "18   9.310724          3688.643790\n",
       "17   8.793517          3677.291748\n",
       "16   8.276310          3665.177950\n",
       "15   7.759103          3652.197174\n",
       "14   7.241897          3638.223408\n",
       "13   6.724690          3623.099041\n",
       "12   6.207483          3606.627059\n",
       "11   5.690276          3588.555074\n",
       "10   5.173069          3568.553637\n",
       "9    4.655862          3546.178007\n",
       "8    4.138655          3520.809530\n",
       "7    3.621448          3501.648139\n",
       "6    3.104241          3479.483210\n",
       "5    2.587034          3454.789342\n",
       "4    2.069828          3437.646537\n",
       "3    1.552621          3412.382392\n",
       "2    1.035414          3359.025888\n",
       "1    0.518207          3221.210533\n",
       "0    0.001000          3036.135352"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder(drop = 'first',sparse_output=False)\n",
    "col_trnf = ColumnTransformer([('OHE', ohe, make_column_selector(dtype_include=object))],\n",
    "                             remainder = 'passthrough',\n",
    "                             verbose_feature_names_out=False)\n",
    "col_tnf = col_trnf.set_output(transform = 'pandas')\n",
    "x = col_trnf.fit_transform(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, random_state = 25, test_size = 0.3)\n",
    "alphas = np.linspace(0.001, 15, 30)\n",
    "l1 = np.linspace(0,1,10)\n",
    "scores = []\n",
    "for a in alphas:\n",
    "    elastic_net = ElasticNet(a)\n",
    "    elastic_net.fit(x_train, y_train)\n",
    "    y_pred = elastic_net.predict(x_test)\n",
    "\n",
    "    scores.append([a, mean_absolute_error(y_test, y_pred)])\n",
    "\n",
    "df_Scores = pd.DataFrame(scores,columns = ['alphas', 'mean_absolute_error'] )\n",
    "df_Scores.sort_values('mean_absolute_error',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a53ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85e5180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
